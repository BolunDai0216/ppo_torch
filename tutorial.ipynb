{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial For ppo_torch\n",
    "\n",
    "In this notebook, I will go through how PPO works and how it is implemented in the `ppo_torch` library. This notebook does not contain any code for training, in the hope that the training loop is self-explanitory. Here is a list of what this notebook will go through:\n",
    "\n",
    "- [Creating multi-layer perceptrons](#mlp)\n",
    "- [Creating Actors](#actors_create)\n",
    "- [Updating Actors](#actors_update)\n",
    "- [Creating Critics](#critics_create)\n",
    "- [Updating Critics](#critics_update)\n",
    "- [Replay Buffer](#replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from actor import ActorContinuous, ActorDiscrete\n",
    "from critic import Critic\n",
    "from mlp import mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Multi-Layer Perceptrons\n",
    "<a id='mlp'></a>\n",
    "\n",
    "The function that creates a multi-layer perceptron, `mlp()`, is defined in `mlp.py`. It takes in two lists\n",
    "\n",
    "- `feature_sizes`: a list of the size of each layer of the mlp\n",
    "- `activation`: a list of the activation functions for each layer of the mlp\n",
    "\n",
    "For example, if the MLP has input size of 8, output size of 4 and 2 hidden layers of size 16, we will define `nn_size = [8, 16, 16, 4]`. Since there are three layers:\n",
    "\n",
    "- Input Layer (8, 16)\n",
    "- Hidden Layer (16, 16)\n",
    "- Output Layer (16, 4)\n",
    "\n",
    "and we set all layers to have ReLU activation, we can define `activations = [nn.ReLU, nn.ReLU, nn.ReLU]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (5): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "nn_sizes = [8, 16, 16, 4]\n",
    "activations = [nn.ReLU, nn.ReLU, nn.ReLU]\n",
    "mlp_model = mlp(nn_sizes, activations)\n",
    "print(mlp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Actors\n",
    "<a id='actors_create'></a>\n",
    "\n",
    "We can set that the `obs_dim = 8` and `act_dim = 4`, we also set the hidden layer have both the `in_feature` and `out_feature` to be 16. Thus, we have `hidden_dim = [16, 16]`. Additionally, we use ReLU for all of the activations, then we have `activations = [nn.ReLU, nn.ReLU, nn.ReLU]`.\n",
    "\n",
    "Using this set up, we can define actors for both continuous and discrete action spaces. First, we define a discrete actor using the `ActorDiscrete` class, which is defined in `actor.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 8\n",
    "act_dim = 4\n",
    "hidden_dim = [16, 16]\n",
    "activations = [nn.ReLU, nn.ReLU, nn.ReLU]\n",
    "\n",
    "actor_d = ActorDiscrete(obs_dim, act_dim, hidden_dim, activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (5): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(actor_d.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the neural network is defined as `actor_d.net`. Next, we see what is the output of `actor_d.forward(obs)`, note this can be directly called using `actor_d(obs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical(logits: torch.Size([1, 4]))\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "obs = torch.ones(1, 8)\n",
    "pi, _ = actor_d(obs)\n",
    "print(pi)\n",
    "print(pi.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the output is not the action, but a probability distribution. Here for discrete actions, the output of `actor_d` is a `Categorical` distribution, we can sample from this distribution `pi` using `pi.sample()`. The output of this sampling is the index of the sampled action, here the output will only be 0, 1, 2, 3.\n",
    "\n",
    "Next we do the same thing for the actor for continuous action spaces using the `ActorContinuous` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 8\n",
    "act_dim = 4\n",
    "hidden_dim = [16, 16]\n",
    "activations = [nn.ReLU, nn.ReLU, nn.ReLU]\n",
    "\n",
    "actor_c = ActorContinuous(obs_dim, act_dim, hidden_dim, activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (5): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(actor_c.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal(loc: torch.Size([1, 4]), scale: torch.Size([1, 4]))\n",
      "tensor([[0.7370, 0.2345, 1.5332, 0.1561]])\n"
     ]
    }
   ],
   "source": [
    "obs = torch.ones(1, 8)\n",
    "pi, _ = actor_c(obs)\n",
    "print(pi)\n",
    "print(pi.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since here we have a continuous action space, the output of `actor_c.forward()` will be a normal distribution with mean `pi.loc`, which is the same as `actor_c.net(obs)` and a fixed standard deviation `pi.scale = np.exp(-0.5)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0431, 0.1402, 0.0000, 0.0000]], grad_fn=<ReluBackward0>),\n",
       " tensor([[0.0431, 0.1402, 0.0000, 0.0000]], grad_fn=<ReluBackward0>),\n",
       " tensor([[0.6065, 0.6065, 0.6065, 0.6065]], grad_fn=<ExpandBackward>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.loc, actor_c.net(obs), pi.scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Actors\n",
    "<a id='actors_update'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Critics\n",
    "<a id='critics_create'></a>\n",
    "\n",
    "We can set the `obs_dim = 8`, since the output is the value function, it always has dimension 1. Similar to the actor, we set the `in_feature`'s and `out_feature`'s to be `hidden_dim = [16, 16]` and all activations to be `activations = [nn.ReLU, nn.ReLU, nn.ReLU]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 8\n",
    "hidden_dim = [16, 16]\n",
    "activations = [nn.ReLU, nn.ReLU, nn.ReLU]\n",
    "critic = Critic(obs_dim, hidden_dim, activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the output of the critic is simply a one dimension value. For both the continuous and discrete actor, the st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0974]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "obs = torch.ones(1, 8)\n",
    "val = critic(obs)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprl_env3",
   "language": "python",
   "name": "deeprl_env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
